{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP 1st week sarcsm dataset tokenizer json .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Lg9wr7RBoXp"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n8d4dGXnwIk",
        "outputId": "89e594fa-52fc-4067-b89c-87888af79d1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sentenses=[\"i love my dog!!!\",\"I, love my cat\",\"you love my dog\",\"do you think my dog is amazing???\",\"hello you fucking dude dog\"]\n",
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts(sentenses)\n",
        "print(tokenizer.word_index)\n",
        "\n",
        "ans = tokenizer.texts_to_sequences(sentenses)\n",
        "print(ans)\n",
        "\n",
        "for i in sentenses:\n",
        "  print(i)\n",
        "  t=tokenizer.texts_to_sequences([i])\n",
        "  print(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'my': 1, 'dog': 2, 'love': 3, 'you': 4, 'i': 5, 'cat': 6, 'do': 7, 'think': 8, 'is': 9, 'amazing': 10, 'hello': 11, 'fucking': 12, 'dude': 13}\n",
            "[[5, 3, 1, 2], [5, 3, 1, 6], [4, 3, 1, 2], [7, 4, 8, 1, 2, 9, 10], [11, 4, 12, 13, 2]]\n",
            "i love my dog!!!\n",
            "[[5, 3, 1, 2]]\n",
            "I, love my cat\n",
            "[[5, 3, 1, 6]]\n",
            "you love my dog\n",
            "[[4, 3, 1, 2]]\n",
            "do you think my dog is amazing???\n",
            "[[7, 4, 8, 1, 2, 9, 10]]\n",
            "hello you fucking dude dog\n",
            "[[11, 4, 12, 13, 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGrvmH-UAVZz",
        "outputId": "af7b0d5d-e3f8-427e-f0ca-3a2ada3c8ee8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sentenses=[\"i love my dog!!!\",\"I, love my cat\",\"you love my dog\",\"do you think my dog is amazing???\",\"hello you fucking dude dog abc xyz pqr\"]\n",
        "tokenizer=Tokenizer(num_words=10,oov_token=\"<oov>\")\n",
        "tokenizer.fit_on_texts(sentenses)\n",
        "word_index=tokenizer.word_index\n",
        "sequence=tokenizer.texts_to_sequences(sentenses)\n",
        "mydata=['i love my amazing dog']\n",
        "myda=tokenizer.texts_to_sequences(['i love my amazing dog you'])\n",
        "print(word_index)\n",
        "print(myda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<oov>': 1, 'my': 2, 'dog': 3, 'love': 4, 'you': 5, 'i': 6, 'cat': 7, 'do': 8, 'think': 9, 'is': 10, 'amazing': 11, 'hello': 12, 'fucking': 13, 'dude': 14, 'abc': 15, 'xyz': 16, 'pqr': 17}\n",
            "[[6, 4, 2, 1, 3, 5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIiFw9h_Zrkx",
        "outputId": "de8087b9-b216-4d5f-984d-23b3fc965075",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t=Tokenizer(oov_token='<oov>')\n",
        "t.fit_on_texts(['hey there','whats up guys'])\n",
        "print(t.word_index)\n",
        "a=['hey whats going there','guys there what']\n",
        "x=t.texts_to_sequences(a)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<oov>': 1, 'hey': 2, 'there': 3, 'whats': 4, 'up': 5, 'guys': 6}\n",
            "[[2, 4, 1, 3], [6, 3, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGEtXZz9LdeU",
        "outputId": "7c1886f7-beec-4c09-bc5d-2e44e508a328",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "sen=[\"i lobve my dog\",\"i love my cat too much\",\"hey there guys i m using whatsapp\"]\n",
        "tokenizer.fit_on_texts(sen)\n",
        "pa=tokenizer.texts_to_sequences(sen)\n",
        "padded=pad_sequences(pa,padding=\"post\")\n",
        "print(padded)\n",
        "print(tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3 1 2 1 0 0 0]\n",
            " [3 1 2 1 1 1 0]\n",
            " [1 1 1 3 1 1 1]]\n",
            "{'<oov>': 1, 'my': 2, 'i': 3, 'dog': 4, 'love': 5, 'you': 6, 'cat': 7, 'do': 8, 'think': 9, 'is': 10, 'amazing': 11, 'hello': 12, 'fucking': 13, 'dude': 14, 'lobve': 15, 'too': 16, 'much': 17, 'hey': 18, 'there': 19, 'guys': 20, 'm': 21, 'using': 22, 'whatsapp': 23}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df_hEN2FqldP",
        "outputId": "b53be5d1-c0e9-4960-d400-ff9765114b6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "import json\n",
        "data = [json.loads(line) for line in open('Sarcasm_Headlines_Dataset.json', 'r')]\n",
        "print(data[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-231d9d6549bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sarcasm_Headlines_Dataset.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Sarcasm_Headlines_Dataset.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lZ8FmYFeNXg",
        "outputId": "d2c34827-856d-4423-fab6-25dcb256fc02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "sen=[]\n",
        "url=[]\n",
        "labels=[]\n",
        "\n",
        "for item in data:\n",
        "  sen.append(item['headline'])\n",
        "  url.append(item['article_link'])\n",
        "  labels.append(item['is_sarcastic'])\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from  tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer=Tokenizer(oov_token=\"<oov>\")\n",
        "tokenizer.fit_on_texts(sen)\n",
        "\n",
        "word_index=tokenizer.word_index\n",
        "\n",
        "print(word_index)\n",
        "\n",
        "sequences=tokenizer.texts_to_sequences(sen)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-de7b236be39d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0msen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'headline'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'article_link'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrAQds-8ln2E"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "trainsen=sen[0:int(0.7*(len(sen)))]\n",
        "testsen=sen[int(0.7*(len(sen))):]\n",
        "trainlab=np.array(labels[0:int(0.7*(len(sen)))])\n",
        "testlab=np.array(labels[int(0.7*(len(sen))):])\n",
        "\n",
        "print(len(trainsen))\n",
        "print(len(testsen))\n",
        "print(len(trainlab))\n",
        "print(len(testlab))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04iPEWxijI2_"
      },
      "source": [
        "model=tf.keras.Sequential([ tf.keras.layers.Embedding(10000,16,input_length=120), tf.keras.layers.Flatten(), tf.keras.layers.Dense(6,activation='relu'), tf.keras.layers.Dense(1,activation='sigmoid') ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEpLmXc4jSBB"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer=Tokenizer(num_words=10000,oov_token=\"<oov>\")\n",
        "tokenizer.fit_on_texts(trainsen)\n",
        "word_index=tokenizer.word_index\n",
        "\n",
        "sequences=tokenizer.texts_to_sequences(trainsen)\n",
        "padded=pad_sequences(sequences,maxlen=120,truncating='post')\n",
        "\n",
        "\n",
        "testing_sequences=tokenizer.texts_to_sequences(testsen)\n",
        "testing_padded=pad_sequences(testing_sequences,maxlen=120,truncating='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea5YYP9ll3_w",
        "outputId": "6e2d86b0-cdbf-4a2b-c6d2-b4119c451fe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-7017d27df329>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EIOuQeOq_vr",
        "outputId": "5cc77026-8368-48fb-83ae-873f75e230a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "print(type(padded))\n",
        "print(type(trainlab))\n",
        "print(type(testing_padded))\n",
        "print(type(testlab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-6d54b4b494cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainlab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_padded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestlab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'trainlab' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjJk_kmepSF8",
        "outputId": "79e83fd4-25bc-4c0e-cade-09684ae0cf4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history=model.fit(padded,trainlab,epochs=30,validation_data=(testing_padded,testlab),verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "585/585 - 2s - loss: 0.5922 - accuracy: 0.6720 - val_loss: 0.4680 - val_accuracy: 0.8368\n",
            "Epoch 2/30\n",
            "585/585 - 2s - loss: 0.3613 - accuracy: 0.8860 - val_loss: 0.3405 - val_accuracy: 0.8554\n",
            "Epoch 3/30\n",
            "585/585 - 2s - loss: 0.1761 - accuracy: 0.9396 - val_loss: 0.3518 - val_accuracy: 0.8557\n",
            "Epoch 4/30\n",
            "585/585 - 2s - loss: 0.0967 - accuracy: 0.9693 - val_loss: 0.3932 - val_accuracy: 0.8502\n",
            "Epoch 5/30\n",
            "585/585 - 2s - loss: 0.0519 - accuracy: 0.9867 - val_loss: 0.4613 - val_accuracy: 0.8465\n",
            "Epoch 6/30\n",
            "585/585 - 2s - loss: 0.0272 - accuracy: 0.9947 - val_loss: 0.5002 - val_accuracy: 0.8441\n",
            "Epoch 7/30\n",
            "585/585 - 2s - loss: 0.0145 - accuracy: 0.9979 - val_loss: 0.5569 - val_accuracy: 0.8399\n",
            "Epoch 8/30\n",
            "585/585 - 2s - loss: 0.0085 - accuracy: 0.9989 - val_loss: 0.6075 - val_accuracy: 0.8386\n",
            "Epoch 9/30\n",
            "585/585 - 2s - loss: 0.0048 - accuracy: 0.9995 - val_loss: 0.6607 - val_accuracy: 0.8388\n",
            "Epoch 10/30\n",
            "585/585 - 2s - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.6903 - val_accuracy: 0.8380\n",
            "Epoch 11/30\n",
            "585/585 - 2s - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.7640 - val_accuracy: 0.8351\n",
            "Epoch 12/30\n",
            "585/585 - 2s - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.7804 - val_accuracy: 0.8351\n",
            "Epoch 13/30\n",
            "585/585 - 2s - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.7994 - val_accuracy: 0.8348\n",
            "Epoch 14/30\n",
            "585/585 - 2s - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.8614 - val_accuracy: 0.8341\n",
            "Epoch 15/30\n",
            "585/585 - 2s - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.8739 - val_accuracy: 0.8334\n",
            "Epoch 16/30\n",
            "585/585 - 2s - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.9177 - val_accuracy: 0.8325\n",
            "Epoch 17/30\n",
            "585/585 - 2s - loss: 7.5184e-04 - accuracy: 0.9997 - val_loss: 0.9663 - val_accuracy: 0.8314\n",
            "Epoch 18/30\n",
            "585/585 - 2s - loss: 9.4282e-04 - accuracy: 0.9996 - val_loss: 1.0454 - val_accuracy: 0.8285\n",
            "Epoch 19/30\n",
            "585/585 - 2s - loss: 8.8925e-04 - accuracy: 0.9996 - val_loss: 1.0373 - val_accuracy: 0.8280\n",
            "Epoch 20/30\n",
            "585/585 - 2s - loss: 0.0010 - accuracy: 0.9996 - val_loss: 1.1648 - val_accuracy: 0.8242\n",
            "Epoch 21/30\n",
            "585/585 - 2s - loss: 8.4707e-04 - accuracy: 0.9997 - val_loss: 1.0562 - val_accuracy: 0.8283\n",
            "Epoch 22/30\n",
            "585/585 - 2s - loss: 6.7962e-04 - accuracy: 0.9996 - val_loss: 1.2068 - val_accuracy: 0.8254\n",
            "Epoch 23/30\n",
            "585/585 - 2s - loss: 6.7707e-04 - accuracy: 0.9996 - val_loss: 1.2754 - val_accuracy: 0.8245\n",
            "Epoch 24/30\n",
            "585/585 - 2s - loss: 7.2842e-04 - accuracy: 0.9997 - val_loss: 1.1721 - val_accuracy: 0.8272\n",
            "Epoch 25/30\n",
            "585/585 - 2s - loss: 8.0023e-04 - accuracy: 0.9996 - val_loss: 1.1752 - val_accuracy: 0.8244\n",
            "Epoch 26/30\n",
            "585/585 - 2s - loss: 7.0345e-04 - accuracy: 0.9997 - val_loss: 1.2014 - val_accuracy: 0.8260\n",
            "Epoch 27/30\n",
            "585/585 - 2s - loss: 8.3145e-04 - accuracy: 0.9996 - val_loss: 1.2053 - val_accuracy: 0.8264\n",
            "Epoch 28/30\n",
            "585/585 - 2s - loss: 6.5513e-04 - accuracy: 0.9997 - val_loss: 1.2329 - val_accuracy: 0.8254\n",
            "Epoch 29/30\n",
            "585/585 - 2s - loss: 5.5759e-04 - accuracy: 0.9997 - val_loss: 1.2210 - val_accuracy: 0.8260\n",
            "Epoch 30/30\n",
            "585/585 - 2s - loss: 8.9295e-04 - accuracy: 0.9996 - val_loss: 1.2244 - val_accuracy: 0.8210\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEp7So6Biiwj"
      },
      "source": [
        "#Assignment of NLP paawansir"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb23r3RjPyc0",
        "outputId": "6aee5595-953c-4723-a859-dc09b3095230",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "#usage of appropriate libraries \n",
        "import nltk,textblob\n",
        "from nltk import word_tokenize\n",
        "from textblob import TextBlob\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "#reading the data from text file\n",
        "corpus=\"The new era of Deep learnning has foound many widespred uses in diverse fields such as Science, Fashion, Game, Medical,\\nHealth etc. which has gained a huge attention for the researchers. Recently, Generative Adversarial Network (GAN) has crucial\\ncontribution in the field of medical image analysis, along with diferent variants of GAN it enhances the capability to resolve the\\nchallenging problems in medical field which leads to the betterment of healthcar technologies. Furthermore, GAN has proven to\\nbe useful, to synthesize images that can resolve the scarcity of real trainng data especially in medical and healthcare field of\\nresarch. In this paper, we present an attempt to improve dataset for CT scan images of stomach cancer using GAN approaches to\\nvarious fields of medical image analysis. The paper also provides a sttistical comparison of generated images which are found to\\nbe of high quality.\"\n",
        "\n",
        "#spelling correction\n",
        "correct_spelled=str(TextBlob(corpus).correct())\n",
        "corpus=correct_spelled\n",
        "\n",
        "#tokenization\n",
        "words=word_tokenize(corpus)\n",
        "\n",
        "#pos tagging \n",
        "pos_tags=nltk.pos_tag(words)\n",
        "\n",
        "#stopwords removal\n",
        "stop_words=stopwords.words('english')\n",
        "without_stopwords=' '.join([word for word in words if word not in stop_words])\n",
        "\n",
        "#stemming and printing first 10 tokens\n",
        "stemmer=nltk.stem.PorterStemmer()\n",
        "stemmed_word_list=[stemmer.stem(word) for word in words]\n",
        "stemmed_text=' '.join(stemmed_word_list)\n",
        "print(stemmed_word_list[:10])\n",
        "\n",
        "\n",
        "#lemmatization and printing first 10 tokens\n",
        "lemmatizer = WordNetLemmatizer() \n",
        "lemmatized_word_list=[lemmatizer.lemmatize(word) for word in words]\n",
        "lemmatized_text=' '.join(lemmatized_word_list)\n",
        "print(lemmatized_word_list[:10])\n",
        "\n",
        "\n",
        "#sentence boundary detection and printing the total number  of sentences\n",
        "sentences=sent_tokenize(corpus)\n",
        "print(\"total no  of sentecnes:\"+str(len(sentences)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-482c609eb19d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#tokenization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#pos tagging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserver_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \"\"\"\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     return [token for sent in sentences\n\u001b[1;32m    130\u001b[0m             for token in _treebank_word_tokenizer.tokenize(sent)]\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \"\"\"\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raw'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nltk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'file'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/lib/nltk_data'\n    - ''\n**********************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO98W1MejUc5"
      },
      "source": [
        "s=\"The new era of Deep learnning has foound many widespred uses in diverse fields such as Science, Fashion, Game, Medical,\\nHealth etc. which has gained a huge attention for the researchers. Recently, Generative Adversarial Network (GAN) has crucial\\ncontribution in the field of medical image analysis, along with diferent variants of GAN it enhances the capability to resolve the\\nchallenging problems in medical field which leads to the betterment of healthcar technologies. Furthermore, GAN has proven to\\nbe useful, to synthesize images that can resolve the scarcity of real trainng data especially in medical and healthcare field of\\nresarch. In this paper, we present an attempt to improve dataset for CT scan images of stomach cancer using GAN approaches to\\nvarious fields of medical image analysis. The paper also provides a sttistical comparison of generated images which are found to\\nbe of high quality.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyImW8OKkO_X",
        "outputId": "97435903-7bb0-4d79-8c37-baf3c33f0c2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "s=s.replace(\"\\n\",\" \")\n",
        "print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The new era of Deep learnning has foound many widespred uses in diverse fields such as Science, Fashion, Game, Medical, Health etc. which has gained a huge attention for the researchers. Recently, Generative Adversarial Network (GAN) has crucial contribution in the field of medical image analysis, along with diferent variants of GAN it enhances the capability to resolve the challenging problems in medical field which leads to the betterment of healthcar technologies. Furthermore, GAN has proven to be useful, to synthesize images that can resolve the scarcity of real trainng data especially in medical and healthcare field of resarch. In this paper, we present an attempt to improve dataset for CT scan images of stomach cancer using GAN approaches to various fields of medical image analysis. The paper also provides a sttistical comparison of generated images which are found to be of high quality.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CsbiDObk_IS",
        "outputId": "fedb0025-af7f-4611-d11e-1669521404d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwd-30I2mcF1",
        "outputId": "6096246d-cbbb-4d66-d2b8-03e774be1283",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "corpus=s\n",
        "corpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The new era of Deep learnning has foound many widespred uses in diverse fields such as Science, Fashion, Game, Medical, Health etc. which has gained a huge attention for the researchers. Recently, Generative Adversarial Network (GAN) has crucial contribution in the field of medical image analysis, along with diferent variants of GAN it enhances the capability to resolve the challenging problems in medical field which leads to the betterment of healthcar technologies. Furthermore, GAN has proven to be useful, to synthesize images that can resolve the scarcity of real trainng data especially in medical and healthcare field of resarch. In this paper, we present an attempt to improve dataset for CT scan images of stomach cancer using GAN approaches to various fields of medical image analysis. The paper also provides a sttistical comparison of generated images which are found to be of high quality.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5X4AJDJnJRE",
        "outputId": "de0367d6-c500-48cf-e55e-89b612d77abc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "correct_spelled=str(TextBlob(corpus).correct())\n",
        "corpus=correct_spelled\n",
        "corpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The new era of Deep learning has found many widespread uses in diverse fields such as Science, Fashion, Same, Medical, Health etc. which has gained a huge attention for the researches. Recently, Generative Adversarial Network (GAN) has crucial contribution in the field of medical image analysis, along with different variant of GAN it enhanced the capability to resolve the challenging problems in medical field which leads to the betterment of healthcar technologies. Furthermore, GAN has prove to be useful, to synthesis images that can resolve the scarcity of real training data especially in medical and healthcare field of research. In this paper, we present an attempt to improve dataset for of scan images of stomach cancer using GAN approaches to various fields of medical image analysis. The paper also provides a statistical comparison of generate images which are found to be of high quality.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8yTGbo6nNhQ",
        "outputId": "faf1f439-0137-40c8-9ce4-dd1304b394dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "words=word_tokenize(corpus)\n",
        "\n",
        "#pos tagging \n",
        "pos_tags=nltk.pos_tag(words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axsWjp3zoNZs",
        "outputId": "804de8c3-83df-431e-eff5-04568a9911b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "nltk.download('stopwords')\n",
        "stopwords=stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJo83wGCoUW2",
        "outputId": "3d190615-f00e-4859-9823-2beee4222eba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "words=[word for word in words if word not in stopwords]\n",
        "words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'new',\n",
              " 'era',\n",
              " 'Deep',\n",
              " 'learning',\n",
              " 'found',\n",
              " 'many',\n",
              " 'widespread',\n",
              " 'uses',\n",
              " 'diverse',\n",
              " 'fields',\n",
              " 'Science',\n",
              " ',',\n",
              " 'Fashion',\n",
              " ',',\n",
              " 'Same',\n",
              " ',',\n",
              " 'Medical',\n",
              " ',',\n",
              " 'Health',\n",
              " 'etc',\n",
              " '.',\n",
              " 'gained',\n",
              " 'huge',\n",
              " 'attention',\n",
              " 'researches',\n",
              " '.',\n",
              " 'Recently',\n",
              " ',',\n",
              " 'Generative',\n",
              " 'Adversarial',\n",
              " 'Network',\n",
              " '(',\n",
              " 'GAN',\n",
              " ')',\n",
              " 'crucial',\n",
              " 'contribution',\n",
              " 'field',\n",
              " 'medical',\n",
              " 'image',\n",
              " 'analysis',\n",
              " ',',\n",
              " 'along',\n",
              " 'different',\n",
              " 'variant',\n",
              " 'GAN',\n",
              " 'enhanced',\n",
              " 'capability',\n",
              " 'resolve',\n",
              " 'challenging',\n",
              " 'problems',\n",
              " 'medical',\n",
              " 'field',\n",
              " 'leads',\n",
              " 'betterment',\n",
              " 'healthcar',\n",
              " 'technologies',\n",
              " '.',\n",
              " 'Furthermore',\n",
              " ',',\n",
              " 'GAN',\n",
              " 'prove',\n",
              " 'useful',\n",
              " ',',\n",
              " 'synthesis',\n",
              " 'images',\n",
              " 'resolve',\n",
              " 'scarcity',\n",
              " 'real',\n",
              " 'training',\n",
              " 'data',\n",
              " 'especially',\n",
              " 'medical',\n",
              " 'healthcare',\n",
              " 'field',\n",
              " 'research',\n",
              " '.',\n",
              " 'In',\n",
              " 'paper',\n",
              " ',',\n",
              " 'present',\n",
              " 'attempt',\n",
              " 'improve',\n",
              " 'dataset',\n",
              " 'scan',\n",
              " 'images',\n",
              " 'stomach',\n",
              " 'cancer',\n",
              " 'using',\n",
              " 'GAN',\n",
              " 'approaches',\n",
              " 'various',\n",
              " 'fields',\n",
              " 'medical',\n",
              " 'image',\n",
              " 'analysis',\n",
              " '.',\n",
              " 'The',\n",
              " 'paper',\n",
              " 'also',\n",
              " 'provides',\n",
              " 'statistical',\n",
              " 'comparison',\n",
              " 'generate',\n",
              " 'images',\n",
              " 'found',\n",
              " 'high',\n",
              " 'quality',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgi1GNswowB0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}